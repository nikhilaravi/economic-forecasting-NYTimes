{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Source code for sentinet: http://www.nltk.org/_modules/nltk/corpus/reader/sentiwordnet.html\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A simple function to obtain the overall sentimate of a text chunk\n",
    "# Method: tokenise the text chunk, obtain the sentiment score of each token, then take mean average.\n",
    "# Note: you may need to separately install sentiwordnet: nltk.download('sentiwordnet')\n",
    "\n",
    "## synsets based on context\n",
    "## phrases/tokens \n",
    "\n",
    "## classify words as noun/adjectives\n",
    "\n",
    "# unsupervised split between adjectives \n",
    "\n",
    "def simple_sentiment(text_chunk):\n",
    "    cumulative_pos_sentiment = 0\n",
    "    cumulative_neg_sentiment = 0\n",
    "    index = 0\n",
    "    \n",
    "    # Tokenizing the sample text\n",
    "    tokens=nltk.word_tokenize(text_chunk)\n",
    "    # Removing words of lenght 2 or less\n",
    "    tokens = [i for i in tokens if len(i)>=3]\n",
    "    print 'Words before cleaning', len(tokens)\n",
    "    # remove stop words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    print 'Words after cleaning', len(tokens)\n",
    "    \n",
    "    # a/n/v/r represent adjective/noun/verb/adverb respectively. They are used to index the sentinet dictionary.\n",
    "    for i in tokens:\n",
    "        if len(list(swn.senti_synsets(i, 'a')))>0:\n",
    "            cumulative_pos_sentiment += list(swn.senti_synsets(i, 'a'))[0].pos_score()\n",
    "            cumulative_neg_sentiment += list(swn.senti_synsets(i, 'a'))[0].neg_score()\n",
    "            index +=1\n",
    "        elif len(list(swn.senti_synsets(i, 'n')))>0:\n",
    "            cumulative_pos_sentiment += list(swn.senti_synsets(i, 'n'))[0].pos_score()\n",
    "            cumulative_neg_sentiment += list(swn.senti_synsets(i, 'n'))[0].neg_score()\n",
    "            index +=1\n",
    "        elif len(list(swn.senti_synsets(i, 'v')))>0:\n",
    "            cumulative_pos_sentiment += list(swn.senti_synsets(i, 'v'))[0].pos_score()\n",
    "            cumulative_neg_sentiment += list(swn.senti_synsets(i, 'v'))[0].neg_score()\n",
    "            index +=1\n",
    "        elif len(list(swn.senti_synsets(i, 'r')))>0:\n",
    "            cumulative_pos_sentiment += list(swn.senti_synsets(i, 'r'))[0].pos_score()\n",
    "            cumulative_neg_sentiment += list(swn.senti_synsets(i, 'r'))[0].neg_score()\n",
    "            index +=1\n",
    "        \n",
    "    avg_pos_sentiment = cumulative_pos_sentiment / float(index)\n",
    "    avg_neg_sentiment = cumulative_neg_sentiment / float(index)\n",
    "    \n",
    "    print('Positive sentiment:',avg_pos_sentiment)\n",
    "    print('Negative sentiment:',avg_neg_sentiment)\n",
    "    \n",
    "    return (avg_pos_sentiment,avg_neg_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words before cleaning 636\n",
      "Words after cleaning 444\n",
      "('Positive sentiment:', 0.0845771144278607)\n",
      "('Negative sentiment:', 0.04695273631840796)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0845771144278607, 0.04695273631840796)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = 'There\\'s no time to waste,\"Over the past few months, President Clinton has lost few opportunities to sing the praises of his favourite book. In November, he told a conference attended by Tony Blair that it was no longer necessary to choose between growth and environment. He took as evidence Natural Capitalism, The Next Industrial Revolution (Paul Hawken and Amory and Hunter Lovins, Earthscan, pounds 18.99), which \\'proves beyond argument that there are presently available technologies, and those just on the horizon, which will permit us to get richer by cleaning, not by spoiling, the environment. This is a huge deal,\\' Clinton said.   It\\'s a suitably millennial claim. The authors argue that \\'capitalism, as practised, is a financially profitable, nonsustainable aberration in human development... [which] does not fully conform to its own accounting principles. It liquidates its capital and calls it income. It neglects to assign any value to the largest stocks of capital it employs, the natural resources and living systems, as well as the social and cultural systems that are the basis of human capital.\\'   Companies, as has been well said, are brilliant externalising machines, pocketing the profits and shunting the costs of their enterprise on to the collectivity. Thus, the NHS pays for the profits of big tobacco, and the Government subsidises cars by building roads. Put it another way, business is a free rider on the environment and the services it provides, services which have been tentatively valued by Nature magazine at $36 trillion annually, roughly the same as world GDP.   The reason business is so profligate with the the environment (the \\'natural capital\\' of the book) is that its goods are assumed by economists to be free and infinitely substitutable. So they are uncosted. But in reality they are not free. They are produced by the earth\\'s 3.8-billion-year store of natural capital which, as the authors rehearse with hair-raising thoroughness, is being eroded so fast that by the end of this century there will be little left. And there is no conceivable substitute, for example, for the biosphere\\'s ability to produce oxygen.   The authors manage to recast this rush to disaster as a story with a (potentially) happier ending. Their grounds for optimism are partly familiar American technological optimism, if natural resources were treated as scarce and expensive, then nanotechnology and biotechnology could multiply four or even tenfold the outputs from today\\'s inputs. Hence Clinton\\'s enthusiasm.   But more crucial to the project is a complete mental flip of what an \\'output\\' consists of (as Edwin Land once said, a great idea is often \\'not having a new thought but stopping having an old one\\').   At present, it is entirely conceivable that one-quarter or even half of the GDP of advanced countries makes not value but waste. Most industrial processes, and the economy as a whole, are inefficient , at best achieving 10 per cent of their potential likewise their products. A car uses just 1 per cent of the energy it burns to propel the driver, the rest to warm the atmosphere, deafen pedestrians and shift ponderous steel boxes between traffic jams.   Moreover, waste is cumulative, so an increasing income has to be spent on alleviating growth\\'s byproducts, pollution, traffic accidents and congestion, crime. Hence the phenomenon of uneconomic growth, where increases in nominal wealth produce no net gain in quality of life or standard of living: in real terms 80 per cent of Americans are no better off than they were in 1979.   However, the grossness of the waste is, say the authors, also a measure of the huge potential for improvement if the spiral changed to virtuous. The secret is taking a systems view in which it is always more expensive to get rid of waste than to design it out in the first place. Given the wastefulness of most current systems, improvements of 10 to 100 times in overall efficiency are possible even with existing technology.   Much of what the Lovins and Hawken propose is not new. Frances Cairncross wrote about costing the earth 10 years ago, and Richard Schonberger coined the term \\'frugal manufacturing\\' in the 1980s. What is new is the way these ideas are brought together in a systems approach to business and the environment, and the coopting of markets as the mechanism which can be used to turn things around.   There is some irony here, of course. The greatest obstacle to \\'natural capitalism\\' in practice will be the vested interests and special pleading of those most vociferous champions of capitalist orthodoxy, US companies, which emerge from this book the masters of the perverse, not to mention grotesque, hidden subsidy, whether of agriculture, cars, or their wealthy executives.   Persuading them to confront their own bad faith will be no easy matter. But, as someone once said, the economy is a wholly-owned subsidiary of the environment, and time is running out for the parent to bring it to heel.'\n",
    "simple_sentiment(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/Cellar/apache-spark/1.5.2/libexec'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = ['Year', 'Week Start', 'Week End', 'Section', 'Number', 'Headline', 'Body Text']\n",
    "articles_df = pd.read_csv('https://s3.amazonaws.com/cs109data/articles_db.csv', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Week Start</th>\n",
       "      <th>Week End</th>\n",
       "      <th>Section</th>\n",
       "      <th>Number</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body Text</th>\n",
       "      <th>Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>There's no time to waste</td>\n",
       "      <td>Over the past few months, President Clinton ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>1</td>\n",
       "      <td>Ford staff threaten strike</td>\n",
       "      <td>Leaders of salaried staff at Ford are threaten...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>2</td>\n",
       "      <td>There's no time to waste</td>\n",
       "      <td>Over the past few months, President Clinton ha...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>3</td>\n",
       "      <td>Cybersquatters with an eye for domain chance</td>\n",
       "      <td>What's in a domain name? Loadsamoney, apparent...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>4</td>\n",
       "      <td>Clicks and mortar leave property crumbling away</td>\n",
       "      <td>The property market looks in pretty good healt...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>5</td>\n",
       "      <td>Labour isn't working hard enough</td>\n",
       "      <td>Few people I know would dissent from the propo...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>6</td>\n",
       "      <td>Dunces excel in the knowledge economy</td>\n",
       "      <td>While all the fashionable blather is of a know...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>7</td>\n",
       "      <td>Russia Y2K bill 'shows West overreacted'</td>\n",
       "      <td>Russia spent just $200 million on preparing fo...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>8</td>\n",
       "      <td>Briefcase</td>\n",
       "      <td>BUY... Domino's Pizza company, which last week...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2000</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>2000-01-09</td>\n",
       "      <td>business</td>\n",
       "      <td>9</td>\n",
       "      <td>TransTec duo kept silent on £11m claim</td>\n",
       "      <td>Two former executive directors of TransTec, th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Week Start    Week End   Section  Number  \\\n",
       "0  2000  2000-01-03  2000-01-09  business       0   \n",
       "0  2000  2000-01-03  2000-01-09  business       1   \n",
       "0  2000  2000-01-03  2000-01-09  business       2   \n",
       "0  2000  2000-01-03  2000-01-09  business       3   \n",
       "0  2000  2000-01-03  2000-01-09  business       4   \n",
       "0  2000  2000-01-03  2000-01-09  business       5   \n",
       "0  2000  2000-01-03  2000-01-09  business       6   \n",
       "0  2000  2000-01-03  2000-01-09  business       7   \n",
       "0  2000  2000-01-03  2000-01-09  business       8   \n",
       "0  2000  2000-01-03  2000-01-09  business       9   \n",
       "\n",
       "                                          Headline  \\\n",
       "0                         There's no time to waste   \n",
       "0                       Ford staff threaten strike   \n",
       "0                         There's no time to waste   \n",
       "0     Cybersquatters with an eye for domain chance   \n",
       "0  Clicks and mortar leave property crumbling away   \n",
       "0                 Labour isn't working hard enough   \n",
       "0            Dunces excel in the knowledge economy   \n",
       "0         Russia Y2K bill 'shows West overreacted'   \n",
       "0                                        Briefcase   \n",
       "0           TransTec duo kept silent on £11m claim   \n",
       "\n",
       "                                           Body Text  Index  \n",
       "0  Over the past few months, President Clinton ha...      0  \n",
       "0  Leaders of salaried staff at Ford are threaten...      1  \n",
       "0  Over the past few months, President Clinton ha...      2  \n",
       "0  What's in a domain name? Loadsamoney, apparent...      3  \n",
       "0  The property market looks in pretty good healt...      4  \n",
       "0  Few people I know would dissent from the propo...      5  \n",
       "0  While all the fashionable blather is of a know...      6  \n",
       "0  Russia spent just $200 million on preparing fo...      7  \n",
       "0  BUY... Domino's Pizza company, which last week...      8  \n",
       "0  Two former executive directors of TransTec, th...      9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_df['Index'] = range(articles_df.shape[0])\n",
    "articles_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize Spark context\n",
    "import pyspark\n",
    "conf = pyspark.SparkConf().setAppName(\"articles\").setMaster(\"local[*]\")\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1, 2, 3, 4, 5]\n",
    "distData = sc.parallelize(data)\n",
    "distData.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articles_text_top = articles_df[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read tweets & associated airlines into Spark\n",
    "articles_text = sc.parallelize([row['Body Text'] for index, row in articles_df.iterrows()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentiment_articles = articles_text.map(lambda text: simple_sentiment(text.decode('utf-8', 'ignore')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-d7865c99e5ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentiment_articles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/rdd.pyc\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1299\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/pyspark/context.pyc\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         return_value = get_return_value(answer, self.gateway_client,\n\u001b[1;32m    538\u001b[0m                 self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_give_back_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JNetworkError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/1.5.2/libexec/python/lib/py4j-0.8.2.1-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0;31m# Happens when a the other end is dead. There might be an empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    432\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0;32mwhile\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m                             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sentiment_articles.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
